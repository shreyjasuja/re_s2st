{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5U3YBWdWOs4"
      },
      "source": [
        "# Evaluation on CoVoST2 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij8C5NCMy_O_"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/shreyjasuja/re_s2st/blob/main/covost2_eval.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook reproduces evaluation results of three models on CoVoST2 dataset:\n",
        "\n",
        "*   [Whisper](https://arxiv.org/pdf/2212.04356.pdf) (Radford et al., 2022)\n",
        "\n",
        "*   [XLS-R](https://arxiv.org/pdf/2111.09296.pdf) (Babu et al., 2021)\n",
        "\n",
        "*   [SeamlessM4T](https://arxiv.org/pdf/2308.11596.pdf) (Barrault et al., 2023)\n",
        "\n",
        "\n",
        "CoVoST 2 is a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of crowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\n",
        "\n",
        "Although most of these models are multi-task models, we would be focusing here on their multilingual translation capabilities\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HYr_7xCnx0PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import torch\n",
        "import collections"
      ],
      "metadata": {
        "id": "0mxabTh83EUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6765d261-7c44-4d59-fe96-09f508a43b0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the dataset"
      ],
      "metadata": {
        "id": "rGO_Ku4tU09I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember from the earlier notebook where we downloaded the audio data, and saved the compressed files. Now we will download a script from our repository which will help extract these files."
      ],
      "metadata": {
        "id": "rDSIWMwl7IZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh -O data/extract_and_cleanup.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBxBaIMDYJof",
        "outputId": "87a6ad42-468a-4eb5-f04e-8f1604beb558"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-15 02:53:58--  https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 934 [text/plain]\n",
            "Saving to: ‘data/extract_and_cleanup.sh’\n",
            "\n",
            "data/extract_and_cl 100%[===================>]     934  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-15 02:53:58 (30.4 MB/s) - ‘data/extract_and_cleanup.sh’ saved [934/934]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let now run that script to extract all our audio files in the required directory structure. This will take approx 8-10 minutes."
      ],
      "metadata": {
        "id": "kQ8d6lvmrYub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WFTnq59Ke6le",
        "outputId": "e298a885-4dc2-4260-85e2-1c727c6ce06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.22 s, sys: 1.48 s, total: 10.7 s\n",
            "Wall time: 7min 35s\n"
          ]
        }
      ],
      "source": [
        "%time !(cd data && chmod +x extract_and_cleanup.sh && ./extract_and_cleanup.sh) &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have only loaded audio files till now. We would also require the trancriptions and/or translations as ground truth for our evaluation. This reference textual data is provided by Hugging face 🤗 Datasets library [here](https://huggingface.co/datasets/covost2)."
      ],
      "metadata": {
        "id": "lbaFdyNi1ksY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try loading some language, say Catalan and see how the data looks like. Language code for Catalan is `ca`."
      ],
      "metadata": {
        "id": "CFzFfYNV2na2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_dataset(\"covost2\",\"ca_en\",data_dir=\"data/ca\",split=\"test\",trust_remote_code=True)"
      ],
      "metadata": {
        "id": "IN1hgmDV275r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1327b24-d374-4bdf-a65b-68ea3737ef22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading builder script: 100%|██████████| 6.96k/6.96k [00:00<00:00, 2.54MB/s]\n",
            "Downloading readme: 100%|██████████| 24.4k/24.4k [00:00<00:00, 9.37MB/s]\n",
            "Downloading data: 100%|██████████| 5.02M/5.02M [00:00<00:00, 13.7MB/s]\n",
            "Generating train split: 100%|██████████| 95854/95854 [00:10<00:00, 9333.54 examples/s] \n",
            "Generating validation split: 100%|██████████| 12730/12730 [00:02<00:00, 6074.45 examples/s]\n",
            "Generating test split: 100%|██████████| 12730/12730 [00:02<00:00, 5999.39 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lets have a look over the data"
      ],
      "metadata": {
        "id": "FatfUTMiU6Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each data point will have the audio file `path` to the audio we downloaded before, an audio `array` which is already sampled at sampling rate of 16,000, transcription in source language as `sentence` and translation to english as `translation` field."
      ],
      "metadata": {
        "id": "eCNFnlR3_gkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "mtMt4kUQ3Zv5",
        "outputId": "344b3b08-2bbb-4d23-d974-0e25cd312094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_id': '03de40b6ecf87f9e1f42719a857b2fbf3b93179bf443e707870f2dda3e53b621248065d52be4dfa6ec462fe118b76b345c19e14063b840813a369c54aab6e1c6',\n",
              " 'file': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
              " 'audio': {'path': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
              "  'array': array([ 2.32830644e-10, -1.74622983e-10, -3.25962901e-09, ...,\n",
              "          9.91155393e-04, -7.40018208e-04, -5.23986295e-04]),\n",
              "  'sampling_rate': 16000},\n",
              " 'sentence': '\"Supervisa l\\'emissió de les resolucions de concessió de l\\'habitació.\"',\n",
              " 'translation': 'Supervises issuance of room concession decisions.',\n",
              " 'id': 'common_voice_ca_19034690'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To store evaluation results under a directory named `results`"
      ],
      "metadata": {
        "id": "qGIN-nWVwk_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "results_directory='results/covost2'\n",
        "if not os.path.exists(results_directory):\n",
        "  os.makedirs(os.path.join(results_directory,'scores'))\n",
        "  os.makedirs(os.path.join(results_directory,'generations'))\n"
      ],
      "metadata": {
        "id": "9RU7VQfdwh8l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divide language in different categories"
      ],
      "metadata": {
        "id": "PWfQG6Dw1VAd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4CZ7zYNUAEB"
      },
      "source": [
        " While evaluating performance in terms of translation capabilities, we need to divide our languages between high, mid and low resource categories depending on what amount of data is available in each language. This distribution has been provided by Babu et al.,2021 in their XLS-R [paper](https://arxiv.org/pdf/2111.09296.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_levels=[\"low_res\",\"mid_res\",\"high_res\"]"
      ],
      "metadata": {
        "id": "OJlsyoIB6CM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_res=['ca','de','fr','es']\n",
        "mid_res=['zh-CN','fa','it','ru','pt']\n",
        "low_res=['mn','ta','lv','et','cy','sl','ja','tr','ar','nl','sv-SE','id']"
      ],
      "metadata": {
        "id": "OZDg567i6Eb7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resource_level_results(scores,model_name):\n",
        "  res_scores=collections.defaultdict(float)\n",
        "  for level in res_levels:\n",
        "    for lang in eval(level):\n",
        "      res_scores[level]+=scores[lang]\n",
        "    res_scores['all']+=res_scores[level]\n",
        "    res_scores[level]/=len(eval(level))\n",
        "  res_scores['all']/=21.0\n",
        "  return {\n",
        "      \"Model\":model_name,\n",
        "      \"High\" : round(res_scores[\"high_res\"],1),\n",
        "      \"Mid\" : round(res_scores[\"mid_res\"],1),\n",
        "      \"Low\" : round(res_scores[\"low_res\"],1),\n",
        "      \"All\" : round(res_scores['all'],1)\n",
        "  }\n",
        ""
      ],
      "metadata": {
        "id": "4cmiXdZfCBoK"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results=[]"
      ],
      "metadata": {
        "id": "WgLs7Gw8FDzJ"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_codes= low_res + mid_res +high_res"
      ],
      "metadata": {
        "id": "RHnH7aF6vyl4"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "6rMztvccFugx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use BLEU score as our evaluation metric. We will source this implementation from the sacrebleu library which is consistent with methodology cited in the research papers. SeamlessM4T also presented the score using same library implementation for *sacrebleu version 2.3.1*"
      ],
      "metadata": {
        "id": "eoCO0yHqGLQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sacre_bleu(translations,gt_translations):\n",
        "  #calculate BLEU score\n",
        "  bleu = sacrebleu.corpus_bleu(translations, [gt_translations])\n",
        "  return round(bleu.score, 3)"
      ],
      "metadata": {
        "id": "wCdJDgbGF8IZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or else we could have also used NLTK's BLEU score implementation, for which scoring function would have look like this."
      ],
      "metadata": {
        "id": "cPR5HNXGH5RY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zPx8JkeGml-4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "def evaluate_nltk_bleu(translations,gt_translations):\n",
        "  references = [[word_tokenize(ref)] for ref in gt_translations]\n",
        "  candidates = [word_tokenize(cand) for cand in translations]\n",
        "  bleu_score=corpus_bleu(list_of_references=references,hypotheses=candidates)\n",
        "  return round(bleu_score * 100, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AY5FCQD1RuU"
      },
      "source": [
        "## Evaluate Whisper model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are multiple whisper mode with varying size. Out of these `large-v2` being the largest of all, tends to perform best. So, we reproduce the results for Whisper large-v2 model for comparative analysis."
      ],
      "metadata": {
        "id": "g6TpWVQA6RRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "bWOfDuX-UgJD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wNa6oB8WofoD"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWcM0iMlplvZ",
        "outputId": "ddec66d0-9897-4d1a-90ba-1134ddaa945a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 1,541,384,960 parameters.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6zRjGcQUx5Q"
      },
      "source": [
        "Below is the function which runs a source langauge to infer over X-eng translations.\n",
        "\n",
        "The parameters defined under `options` is consistent with the example [notebook](https://github.com/openai/whisper/blob/main/notebooks/Multilingual_ASR.ipynb) shared by Whisper for multilingual translation on its github implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference"
      ],
      "metadata": {
        "id": "8Y3EDuSNUkX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sSaBRfdy1mfy"
      },
      "outputs": [],
      "source": [
        "def whisper_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  options = dict(language=src_lang, beam_size=5, best_of=5)\n",
        "  # transcribe_options = dict(task=\"transcribe\",**options))\n",
        "  translate_options = dict(task=\"translate\",**options)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "  # transcriptions = []\n",
        "  # gt_transcripts=[]\n",
        "\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio = item['file']\n",
        "\n",
        "      translation = model.transcribe(audio, **translate_options)[\"text\"]\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "      # transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n",
        "      # transcriptions.append(transcription)\n",
        "      # gt_transcripts.append(item['sentence'])\n",
        "  return translations, gt_translations\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EjE17ileSj_w"
      },
      "outputs": [],
      "source": [
        "whisper_bleu_score = collections.defaultdict(float)\n",
        "whisper_translations = collections.defaultdict(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tGSG328iA2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e48094-a810-4741-f22f-14bcb98d3429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 1464/1759 [1:41:57<13:19,  2.71s/it]"
          ]
        }
      ],
      "source": [
        "for src in lang_codes:\n",
        "  translations, ground_truth = whisper_inference(src)\n",
        "  whisper_translations[src] = translations\n",
        "  whisper_bleu_score[src] = evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "  with open(os.path.join(results_directory,'scores','whisper_eval.json'), 'w') as f:\n",
        "    json.dump(whisper_bleu_score, f, indent=4)\n",
        "  with open(os.path.join(results_directory,'generations','whisper_translations.json'), 'w') as f:\n",
        "    json.dump(whisper_translations, f, indent=4)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_bleu_score"
      ],
      "metadata": {
        "id": "mXzwDt9L_Wsn",
        "outputId": "5143b261-dbe5-4bd5-dbcc-c25c77f21f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fr': 35.453,\n",
              " 'de': 34.886,\n",
              " 'es': 39.56,\n",
              " 'ca': 30.76,\n",
              " 'it': 36.066,\n",
              " 'ru': 42.257,\n",
              " 'zh-CN': 15.964,\n",
              " 'pt': 50.954,\n",
              " 'fa': 17.683,\n",
              " 'et': 12.717,\n",
              " 'mn': 0.136,\n",
              " 'nl': 40.06,\n",
              " 'tr': 27.228,\n",
              " 'ar': 37.944,\n",
              " 'sv-SE': 41.77,\n",
              " 'lv': 12.57,\n",
              " 'sl': 19.459,\n",
              " 'ta': 3.748,\n",
              " 'ja': 24.571,\n",
              " 'id': 46.6,\n",
              " 'cy': 19.088}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resource-level results"
      ],
      "metadata": {
        "id": "t7rcdz1oUoqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resource_level_results(whisper_bleu_score, \"Whisper large-v2\"))"
      ],
      "metadata": {
        "id": "PDfyFUdPOw48",
        "outputId": "0c429dde-c8d2-417a-ba9e-a309259d277e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model': 'Whisper large-v2', 'High': 35.2, 'Mid': 32.6, 'Low': 23.8, 'All': 28.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.append(resource_level_results(whisper_bleu_score, \"Whisper large-v2\"))"
      ],
      "metadata": {
        "id": "8BSMmXkJFMhf"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clear GPU memory\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YY2R064WJSH5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYrhKqeBeU_G"
      },
      "source": [
        "##Evaluate XLS-R (2B) model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the huggingface 🤗 transformers implementation of XLS-R (2B) model.\n",
        "\n",
        "We would be using `wav2vec2-xls-r-2b-21-to-en` model as it is a encoder-decoder model which has been fine-tuned to support languages in CoVoST2 X-eng translations. The details about which can be found [here](https://huggingface.co/facebook/wav2vec2-xls-r-2b-21-to-en)"
      ],
      "metadata": {
        "id": "5hKq98-nJ0As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗ **Note**: Please beaware that the reference code given for inference at huggingface doesn't work, please use the below implementation"
      ],
      "metadata": {
        "id": "2i9Ndk90LJ9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "8-u9dnlTT_Jl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAboaE2kgyyG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import SpeechEncoderDecoderModel,MBart50Tokenizer\n",
        "from datasets import load_dataset\n",
        "#loading the MBart50Tokenizer as decoder is MBart50 transformer model\n",
        "tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i09XNcgD-3h4"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(\"facebook/wav2vec2-xls-r-2b-21-to-en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwwCHQ6UZnRf"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress UserWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the pipleine function to put together the tokenizer, feature extractor and the actual model"
      ],
      "metadata": {
        "id": "vvpiR5YYOOgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnWbf-JEICo2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "asr=pipeline(model=\"facebook/wav2vec2-xls-r-2b-21-to-en\",tokenizer=tokenizer,feature_extractor=feature_extractor,device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference"
      ],
      "metadata": {
        "id": "7sY-tYCSUFxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRwFVWA1pUte"
      },
      "outputs": [],
      "source": [
        "def xlsr_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio = item['file']\n",
        "\n",
        "      translation = asr(audio)[\"text\"]\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "  return translations, gt_translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiZPjlBJXDD1"
      },
      "outputs": [],
      "source": [
        "xlsr_bleu_score=collections.defaultdict(float)\n",
        "xlsr_translations = collections.defaultdict(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty8crgbd_bfM"
      },
      "outputs": [],
      "source": [
        "for src in lang_codes:\n",
        "    translations, ground_truth=xlsr_inference(src)\n",
        "    xlsr_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "    xlsr_translations[src]=translations\n",
        "    with open(os.path.join(results_directory,'scores','xlsr_eval.json'), 'w') as f:\n",
        "      json.dump(xlsr_bleu_score, f, indent=4)\n",
        "    with open(os.path.join(results_directory,'generations','xlsr_translations.json'), 'w') as f:\n",
        "    json.dump(xlsr_translations, f, indent=4)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpyW1Gmx_jRV",
        "outputId": "df2e5ba6-f86b-4b0b-9771-46ab502d2aa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mn': 1.877,\n",
              " 'ta': 0.613,\n",
              " 'lv': 20.774,\n",
              " 'et': 11.186,\n",
              " 'cy': 14.671,\n",
              " 'sl': 19.117,\n",
              " 'ja': 4.102,\n",
              " 'tr': 16.774,\n",
              " 'ar': 16.991,\n",
              " 'nl': 31.883,\n",
              " 'sv-SE': 30.987,\n",
              " 'id': 16.255,\n",
              " 'zh-CN': 9.475,\n",
              " 'fa': 13.073,\n",
              " 'it': 35.034,\n",
              " 'ru': 39.44,\n",
              " 'pt': 42.012,\n",
              " 'ca': 33.813,\n",
              " 'de': 33.486,\n",
              " 'fr': 37.614,\n",
              " 'es': 39.166}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "xlsr_bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resource-level results"
      ],
      "metadata": {
        "id": "96smowtrULXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resource_level_results(xlsr_bleu_score, \"XLS-R (2B)\"))"
      ],
      "metadata": {
        "id": "R1wSUARKFPcP",
        "outputId": "b9a78351-0714-4e40-e499-c1843155ca35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model': 'XLS-R (2B)', 'High': 36.0, 'Mid': 27.8, 'Low': 15.4, 'All': 22.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.append(resource_level_results(xlsr_bleu_score, \"XLS-R (2B)\"))"
      ],
      "metadata": {
        "id": "_wiLYvYbFTXe"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5TdYiQnS6P"
      },
      "source": [
        "## Evaluate Seamless models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The claims under our study are evaluated on both Seamless medium and large models. Both models differ only in number of parameters, thus overall inference methods remains the same.\n",
        "\n",
        " ❗ **Note** : *In order to evaluate the performance of seamless models on CoVoST2 data, just change the `model_type` according to medium or large models, and run the code under this section.*"
      ],
      "metadata": {
        "id": "vyWW5DLY3RmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_type = \"medium\"\n",
        "model_type = \"large\""
      ],
      "metadata": {
        "id": "ryeCshZX1pq3"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would be using Seamless models added to HuggingFace 🤗 by Facebook, you can find more information about this from the [model card](https://huggingface.co/facebook/seamless-m4t-medium) The code in this section has been adopted from documentation available [here](https://huggingface.co/docs/transformers/v4.38.0/en/model_doc/seamless_m4t#overview)"
      ],
      "metadata": {
        "id": "p7ogv7XLQFT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "DI9oyvC-TFBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1YkQLMTuF8Q",
        "outputId": "c1ffbbaf-a527-47f4-d6cf-b274ebba11b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/cc/.local/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoProcessor, SeamlessM4TModel\n",
        "\n",
        "model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)\n",
        "model.cuda()\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference"
      ],
      "metadata": {
        "id": "MXC0bXPeTKlx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01h2MNzOnibE"
      },
      "outputs": [],
      "source": [
        "def seamless_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio_sample = item['audio']\n",
        "      audio_inputs = processor(audios=audio_sample[\"array\"], return_tensors=\"pt\",sampling_rate=16000)\n",
        "      audio_inputs = {k: v.to('cuda') for k, v in audio_inputs.items()}\n",
        "      output_tokens = model.generate(**audio_inputs, tgt_lang=\"eng\",generate_speech=False)\n",
        "      translation=processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "  return translations, gt_translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "WDEWrOs1pzYE"
      },
      "outputs": [],
      "source": [
        "#dictionaries to store BLEU score and translations\n",
        "seamless_bleu_score=collections.defaultdict(float)\n",
        "seamless_translations=collections.defaultdict(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLJm88V5t1DY",
        "outputId": "7ce40f6a-d72a-4bf1-e4d6-042c1666e56b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1759/1759 [12:11<00:00,  2.41it/s]\n",
            "100%|██████████| 786/786 [03:29<00:00,  3.75it/s]\n",
            "100%|██████████| 1629/1629 [06:33<00:00,  4.14it/s]\n",
            "100%|██████████| 1571/1571 [13:28<00:00,  1.94it/s]\n",
            "100%|██████████| 690/690 [03:42<00:00,  3.10it/s]\n",
            "100%|██████████| 360/360 [01:46<00:00,  3.38it/s]\n",
            "100%|██████████| 684/684 [03:21<00:00,  3.40it/s]\n",
            "100%|██████████| 1629/1629 [08:26<00:00,  3.21it/s]\n",
            "100%|██████████| 1695/1695 [07:31<00:00,  3.76it/s]\n",
            "100%|██████████| 1699/1699 [08:25<00:00,  3.36it/s]\n",
            "100%|██████████| 1595/1595 [06:42<00:00,  3.97it/s]\n",
            "100%|██████████| 844/844 [03:24<00:00,  4.12it/s]\n",
            "100%|██████████| 4898/4898 [32:36<00:00,  2.50it/s]\n",
            "100%|██████████| 3445/3445 [17:31<00:00,  3.28it/s]\n",
            "100%|██████████| 8951/8951 [56:18<00:00,  2.65it/s]\n",
            "100%|██████████| 6300/6300 [41:09<00:00,  2.55it/s]\n",
            "100%|██████████| 4023/4023 [20:34<00:00,  3.26it/s]\n",
            "100%|██████████| 12730/12730 [1:18:42<00:00,  2.70it/s]\n",
            " 50%|█████     | 6766/13511 [40:45<37:00,  3.04it/s]"
          ]
        }
      ],
      "source": [
        "for src in lang_codes:\n",
        "    translations, ground_truth=seamless_inference(src)\n",
        "    seamless_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "    seamless_translations[src]=translations\n",
        "\n",
        "    with open(os.path.join(results_directory,'scores','seamless_'+model_type+'_eval.json'), 'w') as f:\n",
        "      json.dump(seamless_bleu_score, f, indent=4)\n",
        "    with open(os.path.join(results_directory,'generations','seamless_'+model_type+'_translations.json'), 'w') as f:\n",
        "    json.dump(seamless_translations, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resource-level results"
      ],
      "metadata": {
        "id": "BHurJShtTbcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type))"
      ],
      "metadata": {
        "id": "MD_naXCSPnPr",
        "outputId": "875b1205-ab8c-483d-8eac-1eb26969b810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model': 'Seamless medium', 'High': 37.3, 'Mid': 33.6, 'Low': 28.3, 'All': 31.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.append(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type))"
      ],
      "metadata": {
        "id": "L3OhrFz_Fll9"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type))"
      ],
      "metadata": {
        "id": "-korQRBjPxK_",
        "outputId": "e7e0d3e8-c99c-444f-fb4f-752f0f22a770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Model': 'Seamless large', 'High': 39.3, 'Mid': 36.2, 'Low': 31.9, 'All': 34.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.append(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type))"
      ],
      "metadata": {
        "id": "oHW8a07GHRzL"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregate Results"
      ],
      "metadata": {
        "id": "6VLFk4tKTixN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df= pd.DataFrame(final_results)"
      ],
      "metadata": {
        "id": "_pxAwW4xH7SO"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Zjd9rJBLIRfr",
        "outputId": "e561a79c-ea04-4152-ab11-e17f4e2fa4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Model  High   Mid   Low   All\n",
              "0  Whisper large-v2  35.2  32.6  23.8  28.1\n",
              "1        XLS-R (2B)  36.0  27.8  15.4  22.3\n",
              "2   Seamless medium  37.3  33.6  28.3  31.3\n",
              "3    Seamless large  39.3  36.2  31.9  34.3"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>High</th>\n",
              "      <th>Mid</th>\n",
              "      <th>Low</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Whisper large-v2</td>\n",
              "      <td>35.2</td>\n",
              "      <td>32.6</td>\n",
              "      <td>23.8</td>\n",
              "      <td>28.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XLS-R (2B)</td>\n",
              "      <td>36.0</td>\n",
              "      <td>27.8</td>\n",
              "      <td>15.4</td>\n",
              "      <td>22.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Seamless medium</td>\n",
              "      <td>37.3</td>\n",
              "      <td>33.6</td>\n",
              "      <td>28.3</td>\n",
              "      <td>31.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Seamless large</td>\n",
              "      <td>39.3</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.9</td>\n",
              "      <td>34.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9igvXTGnP8kD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}