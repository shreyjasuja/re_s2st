{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5U3YBWdWOs4"
   },
   "source": [
    "# Evaluation on CoVoST2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij8C5NCMy_O_"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/shreyjasuja/re_s2st/blob/main/covost2_eval.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook make sure you ran notebook 1.`initiate_server.ipynb`. So, that you have a GPU server to get inference over CoVoST2 dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYr_7xCnx0PH"
   },
   "source": [
    "This notebook reproduces evaluation results of three models on CoVoST2 dataset:\n",
    "\n",
    "*   [Whisper](https://arxiv.org/pdf/2212.04356.pdf) (Radford et al., 2022)\n",
    "\n",
    "*   [XLS-R](https://arxiv.org/pdf/2111.09296.pdf) (Babu et al., 2021)\n",
    "\n",
    "*   [SeamlessM4T](https://arxiv.org/pdf/2308.11596.pdf) (Barrault et al., 2023)\n",
    "\n",
    "\n",
    "CoVoST 2 is a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of crowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\n",
    "\n",
    "Although most of these models are multi-task models, we would be focusing here on their multilingual translation capabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mxabTh83EUV",
    "outputId": "6765d261-7c44-4d59-fe96-09f508a43b0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import torch\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGO_Ku4tU09I"
   },
   "source": [
    "### Extract the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDSIWMwl7IZk"
   },
   "source": [
    "Remember from the earlier notebook where we downloaded the audio data, and saved the compressed files. Now we will download a script from our repository which will help extract these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBxBaIMDYJof",
    "outputId": "87a6ad42-468a-4eb5-f04e-8f1604beb558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-15 02:53:58--  https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 934 [text/plain]\n",
      "Saving to: ‘data/extract_and_cleanup.sh’\n",
      "\n",
      "data/extract_and_cl 100%[===================>]     934  --.-KB/s    in 0s      \n",
      "\n",
      "2024-04-15 02:53:58 (30.4 MB/s) - ‘data/extract_and_cleanup.sh’ saved [934/934]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh -O data/extract_and_cleanup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ8d6lvmrYub"
   },
   "source": [
    "Let now run that script to extract all our audio files in the required directory structure. This will take approx 8-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFTnq59Ke6le",
    "outputId": "e298a885-4dc2-4260-85e2-1c727c6ce06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.22 s, sys: 1.48 s, total: 10.7 s\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%time !(cd data && chmod +x extract_and_cleanup.sh && ./extract_and_cleanup.sh) &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbaFdyNi1ksY"
   },
   "source": [
    "We have only loaded audio files till now. We would also require the trancriptions and/or translations as ground truth for our evaluation. This reference textual data is provided by Hugging face 🤗 Datasets library [here](https://huggingface.co/datasets/covost2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFzFfYNV2na2"
   },
   "source": [
    "Lets try loading some language, say Catalan and see how the data looks like. Language code for Catalan is `ca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IN1hgmDV275r",
    "outputId": "e1327b24-d374-4bdf-a65b-68ea3737ef22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.96k/6.96k [00:00<00:00, 2.54MB/s]\n",
      "Downloading readme: 100%|██████████| 24.4k/24.4k [00:00<00:00, 9.37MB/s]\n",
      "Downloading data: 100%|██████████| 5.02M/5.02M [00:00<00:00, 13.7MB/s]\n",
      "Generating train split: 100%|██████████| 95854/95854 [00:10<00:00, 9333.54 examples/s] \n",
      "Generating validation split: 100%|██████████| 12730/12730 [00:02<00:00, 6074.45 examples/s]\n",
      "Generating test split: 100%|██████████| 12730/12730 [00:02<00:00, 5999.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data=load_dataset(\"covost2\",\"ca_en\",data_dir=\"data/ca\",split=\"test\",trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FatfUTMiU6Wd"
   },
   "source": [
    "#### Lets have a look over the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCNFnlR3_gkd"
   },
   "source": [
    "Each data point will have the audio file `path` to the audio we downloaded before, an audio `array` which is already sampled at sampling rate of 16,000, transcription in source language as `sentence` and translation to english as `translation` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtMt4kUQ3Zv5",
    "outputId": "344b3b08-2bbb-4d23-d974-0e25cd312094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '03de40b6ecf87f9e1f42719a857b2fbf3b93179bf443e707870f2dda3e53b621248065d52be4dfa6ec462fe118b76b345c19e14063b840813a369c54aab6e1c6',\n",
       " 'file': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
       " 'audio': {'path': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
       "  'array': array([ 2.32830644e-10, -1.74622983e-10, -3.25962901e-09, ...,\n",
       "          9.91155393e-04, -7.40018208e-04, -5.23986295e-04]),\n",
       "  'sampling_rate': 16000},\n",
       " 'sentence': '\"Supervisa l\\'emissió de les resolucions de concessió de l\\'habitació.\"',\n",
       " 'translation': 'Supervises issuance of room concession decisions.',\n",
       " 'id': 'common_voice_ca_19034690'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Play an audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Assuming 'audio_array' is your sampled audio array and 'fs' is the sampling rate\n",
    "Audio(data['audio']['array'], rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Setup result directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGIN-nWVwk_m"
   },
   "source": [
    "To store evaluation results under a directory named `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RU7VQfdwh8l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "results_directory='results/covost2'\n",
    "if not os.path.exists(results_directory):\n",
    "  os.makedirs(os.path.join(results_directory,'scores'))\n",
    "  os.makedirs(os.path.join(results_directory,'generations'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWfQG6Dw1VAd"
   },
   "source": [
    "## Divide language in different categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4CZ7zYNUAEB"
   },
   "source": [
    " While evaluating performance in terms of translation capabilities, we need to divide our languages between high, mid and low resource categories depending on what amount of data is available in each language. This distribution has been provided by Babu et al.,2021 in their XLS-R [paper](https://arxiv.org/pdf/2111.09296.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OJlsyoIB6CM8"
   },
   "outputs": [],
   "source": [
    "res_levels=[\"low_res\",\"mid_res\",\"high_res\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OZDg567i6Eb7"
   },
   "outputs": [],
   "source": [
    "high_res=['ca','de','fr','es']\n",
    "mid_res=['zh-CN','fa','it','ru','pt']\n",
    "low_res=['mn','ta','lv','et','cy','sl','ja','tr','ar','nl','sv-SE','id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4cmiXdZfCBoK"
   },
   "outputs": [],
   "source": [
    "def resource_level_results(scores,model_name):\n",
    "  res_scores=collections.defaultdict(float)\n",
    "  for level in res_levels:\n",
    "    for lang in eval(level):\n",
    "      res_scores[level]+=scores[lang]\n",
    "    res_scores['all']+=res_scores[level]\n",
    "    res_scores[level]/=len(eval(level))\n",
    "  res_scores['all']/=21.0\n",
    "  return {\n",
    "      \"Model\":model_name,\n",
    "      \"High\" : round(res_scores[\"high_res\"],1),\n",
    "      \"Mid\" : round(res_scores[\"mid_res\"],1),\n",
    "      \"Low\" : round(res_scores[\"low_res\"],1),\n",
    "      \"All\" : round(res_scores['all'],1)\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WgLs7Gw8FDzJ"
   },
   "outputs": [],
   "source": [
    "final_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RHnH7aF6vyl4"
   },
   "outputs": [],
   "source": [
    "lang_codes= low_res + mid_res +high_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rMztvccFugx"
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoCO0yHqGLQl"
   },
   "source": [
    "We will use BLEU score as our evaluation metric. We will source this implementation from the sacrebleu library which is consistent with methodology cited in the research papers. SeamlessM4T also presented the score using same library implementation for *sacrebleu version 2.3.1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCdJDgbGF8IZ"
   },
   "outputs": [],
   "source": [
    "def evaluate_sacre_bleu(translations,gt_translations):\n",
    "  #calculate BLEU score\n",
    "  bleu = sacrebleu.corpus_bleu(translations, [gt_translations])\n",
    "  return round(bleu.score, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPR5HNXGH5RY"
   },
   "source": [
    "Or else we could have also used NLTK's BLEU score implementation, for which scoring function would have look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPx8JkeGml-4"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "def evaluate_nltk_bleu(translations,gt_translations):\n",
    "  references = [[word_tokenize(ref)] for ref in gt_translations]\n",
    "  candidates = [word_tokenize(cand) for cand in translations]\n",
    "  bleu_score=corpus_bleu(list_of_references=references,hypotheses=candidates)\n",
    "  return round(bleu_score * 100, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AY5FCQD1RuU"
   },
   "source": [
    "## Evaluate Whisper model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6TpWVQA6RRw"
   },
   "source": [
    "There are multiple whisper mode with varying size. Out of these `large-v2` being the largest of all, tends to perform best. So, we reproduce the results for Whisper large-v2 model for comparative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWOfDuX-UgJD"
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNa6oB8WofoD"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWcM0iMlplvZ",
    "outputId": "ddec66d0-9897-4d1a-90ba-1134ddaa945a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is multilingual and has 1,541,384,960 parameters.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6zRjGcQUx5Q"
   },
   "source": [
    "Below is the function which runs a source langauge to infer over X-eng translations.\n",
    "\n",
    "The parameters defined under `options` is consistent with the example [notebook](https://github.com/openai/whisper/blob/main/notebooks/Multilingual_ASR.ipynb) shared by Whisper for multilingual translation on its github implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y3EDuSNUkX3"
   },
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sSaBRfdy1mfy"
   },
   "outputs": [],
   "source": [
    "def whisper_inference(src_lang):\n",
    "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
    "\n",
    "  options = dict(language=src_lang.split(\"-\")[0], beam_size=5, best_of=5)\n",
    "  # transcribe_options = dict(task=\"transcribe\",**options))\n",
    "  translate_options = dict(task=\"translate\",**options)\n",
    "\n",
    "  translations = []\n",
    "  gt_translations = []\n",
    "\n",
    "  # transcriptions = []\n",
    "  # gt_transcripts=[]\n",
    "\n",
    "\n",
    "  for item in tqdm(x_en):\n",
    "      audio = item['file']\n",
    "\n",
    "      translation = model.transcribe(audio, **translate_options)[\"text\"]\n",
    "      translations.append(translation)\n",
    "      gt_translations.append(item['translation'])\n",
    "\n",
    "      # transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n",
    "      # transcriptions.append(transcription)\n",
    "      # gt_transcripts.append(item['sentence'])\n",
    "  return translations, gt_translations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EjE17ileSj_w"
   },
   "outputs": [],
   "source": [
    "whisper_bleu_score = collections.defaultdict(float)\n",
    "whisper_translations = collections.defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tGSG328iA2R",
    "outputId": "b17aa8af-c3a8-4fcb-df87-fe638bbe6965"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 674/1759 [49:07<1:49:12,  6.04s/it]"
     ]
    }
   ],
   "source": [
    "for src in lang_codes:\n",
    "  translations, ground_truth = whisper_inference(src)\n",
    "  whisper_translations[src] = translations\n",
    "  whisper_bleu_score[src] = evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
    "  with open(os.path.join(results_directory,'scores','Whisper Large-v2.json'), 'w') as f:\n",
    "    json.dump(whisper_bleu_score, f, indent=4)\n",
    "  with open(os.path.join(results_directory,'generations','Whisper Large-v2.json'), 'w') as f:\n",
    "    json.dump(whisper_translations, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXzwDt9L_Wsn",
    "outputId": "5f02ccdb-bbff-4d3d-bd94-b13276dfaddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'mn': 0.111,\n",
       "             'ta': 4.263,\n",
       "             'lv': 13.738,\n",
       "             'et': 14.77,\n",
       "             'cy': 20.134,\n",
       "             'sl': 21.88,\n",
       "             'ja': 26.42,\n",
       "             'tr': 29.278,\n",
       "             'ar': 37.529,\n",
       "             'nl': 40.541,\n",
       "             'sv-SE': 41.994,\n",
       "             'id': 48.2,\n",
       "             'zh-CN': 16.8,\n",
       "             'fa': 19.449,\n",
       "             'it': 37.045,\n",
       "             'ru': 42.791,\n",
       "             'pt': 52.134,\n",
       "             'ca': 31.572,\n",
       "             'de': 36.404,\n",
       "             'fr': 36.802,\n",
       "             'es': 40.579})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7rcdz1oUoqT"
   },
   "source": [
    "### Resource-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1poRtb94jx_",
    "outputId": "d2c41b77-5915-4e8b-8131-b6738373a152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Whisper Large-v2', 'High': 36.3, 'Mid': 33.6, 'Low': 24.9, 'All': 29.2}\n"
     ]
    }
   ],
   "source": [
    "print(resource_level_results(whisper_bleu_score, \"Whisper Large-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YY2R064WJSH5"
   },
   "outputs": [],
   "source": [
    "#clear GPU memory\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYrhKqeBeU_G"
   },
   "source": [
    "## Evaluate XLS-R (2B) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hKq98-nJ0As"
   },
   "source": [
    "We use the huggingface 🤗 transformers implementation of XLS-R (2B) model.\n",
    "\n",
    "We would be using `wav2vec2-xls-r-2b-21-to-en` model as it is a encoder-decoder model which has been fine-tuned to support languages in CoVoST2 X-eng translations. The details about which can be found [here](https://huggingface.co/facebook/wav2vec2-xls-r-2b-21-to-en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i9Ndk90LJ9J"
   },
   "source": [
    "❗ **Note**: Please beaware that the reference code given for inference at huggingface doesn't work, please use the below implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-u9dnlTT_Jl"
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DAboaE2kgyyG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SpeechEncoderDecoderModel,MBart50Tokenizer\n",
    "from datasets import load_dataset\n",
    "#loading the MBart50Tokenizer as decoder is MBart50 transformer model\n",
    "tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "i09XNcgD-3h4"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\"facebook/wav2vec2-xls-r-2b-21-to-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AwwCHQ6UZnRf"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvpiR5YYOOgg"
   },
   "source": [
    "Using the pipleine function to put together the tokenizer, feature extractor and the actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnWbf-JEICo2"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "asr=pipeline(model=\"facebook/wav2vec2-xls-r-2b-21-to-en\",tokenizer=tokenizer,feature_extractor=feature_extractor,device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sY-tYCSUFxf"
   },
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "RRwFVWA1pUte"
   },
   "outputs": [],
   "source": [
    "def xlsr_inference(src_lang):\n",
    "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
    "\n",
    "  translations = []\n",
    "  gt_translations = []\n",
    "\n",
    "  for item in tqdm(x_en):\n",
    "      audio = item['file']\n",
    "\n",
    "      translation = asr(audio)[\"text\"]\n",
    "      translations.append(translation)\n",
    "      gt_translations.append(item['translation'])\n",
    "\n",
    "  return translations, gt_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TiZPjlBJXDD1"
   },
   "outputs": [],
   "source": [
    "xlsr_bleu_score=collections.defaultdict(float)\n",
    "xlsr_translations = collections.defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ty8crgbd_bfM",
    "outputId": "e634f41e-9961-4f78-e884-cc7152cfd330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1260/1759 [11:48<04:54,  1.69it/s]"
     ]
    }
   ],
   "source": [
    "for src in lang_codes:\n",
    "    translations, ground_truth=xlsr_inference(src)\n",
    "    xlsr_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
    "    xlsr_translations[src]=translations\n",
    "    with open(os.path.join(results_directory,'scores','XLS-R (2B).json'), 'w') as f:\n",
    "      json.dump(xlsr_bleu_score, f, indent=4)\n",
    "    with open(os.path.join(results_directory,'generations','XLS-R (2B).json'), 'w') as f:\n",
    "      json.dump(xlsr_translations, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpyW1Gmx_jRV",
    "outputId": "6456b443-2812-49b1-e030-8caefd0c099e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'mn': 1.558,\n",
       "             'ta': 0.478,\n",
       "             'lv': 19.677,\n",
       "             'et': 11.112,\n",
       "             'cy': 14.11,\n",
       "             'sl': 18.552,\n",
       "             'ja': 3.53,\n",
       "             'tr': 16.894,\n",
       "             'ar': 17.101,\n",
       "             'nl': 31.73,\n",
       "             'sv-SE': 29.515,\n",
       "             'id': 16.443,\n",
       "             'zh-CN': 9.492,\n",
       "             'fa': 12.892,\n",
       "             'it': 34.913,\n",
       "             'ru': 39.504,\n",
       "             'pt': 41.884,\n",
       "             'ca': 33.855,\n",
       "             'de': 33.589,\n",
       "             'fr': 37.628,\n",
       "             'es': 39.146})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsr_bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96smowtrULXm"
   },
   "source": [
    "### Resource-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3zK46Vs4pS8",
    "outputId": "d9ddb67f-4f68-4ff7-8762-ff421326b44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XLS-R (2B)', 'High': 36.1, 'Mid': 27.7, 'Low': 15.1, 'All': 22.1}\n"
     ]
    }
   ],
   "source": [
    "print(resource_level_results(xlsr_bleu_score, \"XLS-R (2B)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4N5_dPvEgolc"
   },
   "outputs": [],
   "source": [
    "#clear GPU memory\n",
    "del asr\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR5TdYiQnS6P"
   },
   "source": [
    "## Evaluate Seamless models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyWW5DLY3RmE"
   },
   "source": [
    "The claims under our study are evaluated on both Seamless medium and large models. Both models differ only in number of parameters, thus overall inference methods remains the same.\n",
    "\n",
    " ❗ **Note** : *In order to evaluate the performance of seamless models on CoVoST2 data, just change the `model_type` according to medium or large models, and run the code under this section.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ryeCshZX1pq3"
   },
   "outputs": [],
   "source": [
    "model_type = \"medium\"\n",
    "# model_type = \"large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7ogv7XLQFT4"
   },
   "source": [
    "We would be using Seamless models added to HuggingFace 🤗 by Facebook, you can find more information about this from the [model card](https://huggingface.co/facebook/seamless-m4t-medium) The code in this section has been adopted from documentation available [here](https://huggingface.co/docs/transformers/v4.38.0/en/model_doc/seamless_m4t#overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI9oyvC-TFBq"
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1YkQLMTuF8Q",
    "outputId": "e0a101c1-6c9e-4e67-c78f-d2c5e5198ecc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, SeamlessM4TModel\n",
    "\n",
    "model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)\n",
    "model.cuda()\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXC0bXPeTKlx"
   },
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "01h2MNzOnibE"
   },
   "outputs": [],
   "source": [
    "def seamless_inference(src_lang):\n",
    "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
    "\n",
    "  translations = []\n",
    "  gt_translations = []\n",
    "\n",
    "\n",
    "  for item in tqdm(x_en):\n",
    "      audio_sample = item['audio']\n",
    "      audio_inputs = processor(audios=audio_sample[\"array\"], return_tensors=\"pt\",sampling_rate=16000)\n",
    "      audio_inputs = {k: v.to('cuda') for k, v in audio_inputs.items()}\n",
    "      output_tokens = model.generate(**audio_inputs, tgt_lang=\"eng\",generate_speech=False)\n",
    "      translation=processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
    "      translations.append(translation)\n",
    "      gt_translations.append(item['translation'])\n",
    "\n",
    "  return translations, gt_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "WDEWrOs1pzYE"
   },
   "outputs": [],
   "source": [
    "#dictionaries to store BLEU score and translations\n",
    "seamless_bleu_score=collections.defaultdict(float)\n",
    "seamless_translations=collections.defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLJm88V5t1DY",
    "outputId": "13290dc7-b46d-4c48-be95-7867f527d4cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1759/1759 [07:10<00:00,  4.09it/s]\n",
      "100%|██████████| 786/786 [02:17<00:00,  5.70it/s]\n",
      "100%|██████████| 1629/1629 [04:14<00:00,  6.41it/s]\n",
      "100%|██████████| 1571/1571 [08:46<00:00,  2.98it/s]\n",
      "100%|██████████| 690/690 [02:20<00:00,  4.91it/s]\n",
      "100%|██████████| 360/360 [00:56<00:00,  6.39it/s]\n",
      "100%|██████████| 684/684 [02:09<00:00,  5.30it/s]\n",
      "100%|██████████| 1629/1629 [05:36<00:00,  4.84it/s]\n",
      "100%|██████████| 1695/1695 [04:18<00:00,  6.55it/s]\n",
      "100%|██████████| 1699/1699 [05:20<00:00,  5.31it/s]\n",
      "100%|██████████| 1595/1595 [03:54<00:00,  6.80it/s]\n",
      "100%|██████████| 844/844 [02:08<00:00,  6.57it/s]\n",
      "100%|██████████| 4898/4898 [21:56<00:00,  3.72it/s]\n",
      " 37%|███▋      | 1262/3445 [04:10<08:15,  4.40it/s]"
     ]
    }
   ],
   "source": [
    "for src in lang_codes:\n",
    "    translations, ground_truth=seamless_inference(src)\n",
    "    seamless_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
    "    seamless_translations[src]=translations\n",
    "\n",
    "    with open(os.path.join(results_directory,'scores','Seamless '+model_type+'.json'), 'w') as f:\n",
    "      json.dump(seamless_bleu_score, f, indent=4)\n",
    "    with open(os.path.join(results_directory,'generations','Seamless '+model_type+'.json'), 'w') as f:\n",
    "      json.dump(seamless_translations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsalytQ1kcX8",
    "outputId": "8646e818-2913-4765-cd5f-c82a9c7ff57e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'mn': 6.996,\n",
       "             'ta': 3.318,\n",
       "             'lv': 22.484,\n",
       "             'et': 21.803,\n",
       "             'cy': 50.784,\n",
       "             'sl': 30.809,\n",
       "             'ja': 16.819,\n",
       "             'tr': 27.575,\n",
       "             'ar': 41.328,\n",
       "             'nl': 35.986,\n",
       "             'sv-SE': 32.714,\n",
       "             'id': 49.474,\n",
       "             'zh-CN': 18.673,\n",
       "             'fa': 23.357,\n",
       "             'it': 37.165,\n",
       "             'ru': 43.014,\n",
       "             'pt': 45.915,\n",
       "             'ca': 35.597,\n",
       "             'de': 35.234,\n",
       "             'fr': 39.121,\n",
       "             'es': 39.075})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seamless_bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHurJShtTbcp"
   },
   "source": [
    "### Resource-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdUJ-6outNiK",
    "outputId": "0b4050b1-cb56-42f2-d96f-3cec345c7f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Seamless medium', 'High': 37.3, 'Mid': 33.6, 'Low': 28.3, 'All': 31.3}\n"
     ]
    }
   ],
   "source": [
    "print(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type)) #medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Duw0qXJHgpud",
    "outputId": "9e840c6b-aebf-456f-9b06-b41358b9c346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Seamless large', 'High': 39.3, 'Mid': 36.2, 'Low': 31.9, 'All': 34.3}\n"
     ]
    }
   ],
   "source": [
    "print(resource_level_results(seamless_bleu_score, \"Seamless \"+model_type))#large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjRMEacP3fXB"
   },
   "source": [
    "## Challanges, we overcame 💪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58Ba6O6k3fXB"
   },
   "source": [
    "1. One major difficulty we initially faced was re-downloading data again and again for repeated experimentation. As the links expire after a certain time, we had to source the links manually for each language, which was a tedious task. We solved it by persisting the CoVoST2 data on the Object Store in the previous notebook.\n",
    "\n",
    "2. The inference code for XLS-R model was not working as expected. We had to modify the code to make it work. (More to be added about this)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
