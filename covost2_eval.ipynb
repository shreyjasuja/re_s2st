{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5U3YBWdWOs4"
      },
      "source": [
        "# Evaluation on CoVoST2 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij8C5NCMy_O_"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/shreyjasuja/re_s2st/blob/main/covost2_eval.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook reproduces evaluation results of three models on CoVoST2 dataset:\n",
        "\n",
        "*   [Whisper](https://arxiv.org/pdf/2212.04356.pdf) (Radford et al., 2022)\n",
        "*   [SeamlessM4T](https://arxiv.org/pdf/2308.11596.pdf) (Barrault et al., 2023)\n",
        "*   [XLS-R](https://arxiv.org/pdf/2111.09296.pdf) (Babu et al., 2021)\n",
        "\n",
        "\n",
        "CoVoST 2 is a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of crowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\n",
        "\n",
        "Although most of these models are multi-task models, we would be focusing here on their multilingual translation capabilities\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HYr_7xCnx0PH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember from the notebook where we downloaded the audio data, and saved the compressed files. Now we will download a script from our repository which will help extract these files."
      ],
      "metadata": {
        "id": "rDSIWMwl7IZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh -O data/extract_and_cleanup.sh"
      ],
      "metadata": {
        "id": "TBxBaIMDYJof",
        "outputId": "87a6ad42-468a-4eb5-f04e-8f1604beb558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-15 02:53:58--  https://raw.githubusercontent.com/shreyjasuja/re_s2st/main/scripts/extract_and_cleanup.sh\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 934 [text/plain]\n",
            "Saving to: â€˜data/extract_and_cleanup.shâ€™\n",
            "\n",
            "data/extract_and_cl 100%[===================>]     934  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-15 02:53:58 (30.4 MB/s) - â€˜data/extract_and_cleanup.shâ€™ saved [934/934]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would now use that script to extract all our audio files in the required directory structure. This will take approx 8-10 minutes."
      ],
      "metadata": {
        "id": "kQ8d6lvmrYub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WFTnq59Ke6le",
        "outputId": "e298a885-4dc2-4260-85e2-1c727c6ce06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.22 s, sys: 1.48 s, total: 10.7 s\n",
            "Wall time: 7min 35s\n"
          ]
        }
      ],
      "source": [
        "%time !(cd data && chmod +x extract_and_cleanup.sh && ./extract_and_cleanup.sh) &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have only loaded audio files till now. We would also require the trancriptions and/or translations as ground truth for our evaluation. This reference textual data is provided by Hugging face ðŸ¤— Datasets library [here](https://huggingface.co/datasets/covost2)."
      ],
      "metadata": {
        "id": "lbaFdyNi1ksY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try loading some language, say Catalan and see how the data looks like. Language code for Catalan is `ca`."
      ],
      "metadata": {
        "id": "CFzFfYNV2na2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import torch\n",
        "import collections"
      ],
      "metadata": {
        "id": "0mxabTh83EUV",
        "outputId": "f600fc99-9f4c-4457-cb9b-db65545140f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/cc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_dataset(\"covost2\",\"ca_en\",data_dir=\"data/ca\",split=\"test\",trust_remote_code=True)"
      ],
      "metadata": {
        "id": "IN1hgmDV275r",
        "outputId": "e1327b24-d374-4bdf-a65b-68ea3737ef22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.96k/6.96k [00:00<00:00, 2.54MB/s]\n",
            "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.4k/24.4k [00:00<00:00, 9.37MB/s]\n",
            "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.02M/5.02M [00:00<00:00, 13.7MB/s]\n",
            "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95854/95854 [00:10<00:00, 9333.54 examples/s] \n",
            "Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12730/12730 [00:02<00:00, 6074.45 examples/s]\n",
            "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12730/12730 [00:02<00:00, 5999.39 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each data point will have the audio file `path` to the audio we downloaded before, an audio `array` which is already sampled at sampling rate of 16,000, transcription in source language as `sentence` and translation to english as `translation` field."
      ],
      "metadata": {
        "id": "eCNFnlR3_gkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "mtMt4kUQ3Zv5",
        "outputId": "344b3b08-2bbb-4d23-d974-0e25cd312094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_id': '03de40b6ecf87f9e1f42719a857b2fbf3b93179bf443e707870f2dda3e53b621248065d52be4dfa6ec462fe118b76b345c19e14063b840813a369c54aab6e1c6',\n",
              " 'file': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
              " 'audio': {'path': '/home/cc/data/ca/clips/common_voice_ca_19034690.mp3',\n",
              "  'array': array([ 2.32830644e-10, -1.74622983e-10, -3.25962901e-09, ...,\n",
              "          9.91155393e-04, -7.40018208e-04, -5.23986295e-04]),\n",
              "  'sampling_rate': 16000},\n",
              " 'sentence': '\"Supervisa l\\'emissiÃ³ de les resolucions de concessiÃ³ de l\\'habitaciÃ³.\"',\n",
              " 'translation': 'Supervises issuance of room concession decisions.',\n",
              " 'id': 'common_voice_ca_19034690'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To store evaluation results under a directory named `results`"
      ],
      "metadata": {
        "id": "qGIN-nWVwk_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "results_directory='results/covost2'\n",
        "if not os.path.exists(results_directory):\n",
        "  os.makedirs(os.path.join(results_directory,'scores'))\n",
        "  os.makedirs(os.path.join(results_directory,'generations'))\n"
      ],
      "metadata": {
        "id": "9RU7VQfdwh8l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divide language in different categories"
      ],
      "metadata": {
        "id": "PWfQG6Dw1VAd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4CZ7zYNUAEB"
      },
      "source": [
        " While evaluating performance in terms of translation capabilities, we need to divide our languages between high, mid and low resource categories depending on what amount of data is available in each language. This distribution has been provided by Babu et al.,2021 in their XLS-R [paper](https://arxiv.org/pdf/2111.09296.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_levels=[\"low_res\",\"mid_res\",\"high_res\"]"
      ],
      "metadata": {
        "id": "OJlsyoIB6CM8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_res=['ca','de','fr','es']\n",
        "mid_res=['zh-CN','fa','it','ru','pt']\n",
        "low_res=['mn','ta','lv','et','cy','sl','ja','tr','ar','nl','sv-SE','id']"
      ],
      "metadata": {
        "id": "OZDg567i6Eb7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_codes= high_res + mid_res +low_res"
      ],
      "metadata": {
        "id": "RHnH7aF6vyl4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "6rMztvccFugx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use BLEU score as our evaluation metric. We will source this implementation from the sacrebleu library which is consistent with methodology cited in the research papers. SeamlessM4T also presented the score using same library implementation for *sacrebleu version 2.3.1*"
      ],
      "metadata": {
        "id": "eoCO0yHqGLQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_sacre_bleu(translations,gt_translations):\n",
        "  #calculate BLEU score\n",
        "  bleu = sacrebleu.corpus_bleu(translations, [gt_translations])\n",
        "  return round(bleu.score, 3)"
      ],
      "metadata": {
        "id": "wCdJDgbGF8IZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or else we could have also used NLTK's BLEU score implementation, for which scoring function would have look like this."
      ],
      "metadata": {
        "id": "cPR5HNXGH5RY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zPx8JkeGml-4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "def evaluate_nltk_bleu(translations,gt_translations):\n",
        "  references = [[word_tokenize(ref)] for ref in gt_translations]\n",
        "  candidates = [word_tokenize(cand) for cand in translations]\n",
        "  bleu_score=corpus_bleu(list_of_references=references,hypotheses=candidates)\n",
        "  return round(bleu_score * 100, 3)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AY5FCQD1RuU"
      },
      "source": [
        "## Load Whisper and do inference on CoVoST2 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are multiple whisper mode with varying size. Out of these `large-v2` being the largest of all, tends to perform best. So, we reproduce the results for Whisper large-v2 model only for comparative analysis."
      ],
      "metadata": {
        "id": "g6TpWVQA6RRw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wNa6oB8WofoD"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWcM0iMlplvZ",
        "outputId": "ddec66d0-9897-4d1a-90ba-1134ddaa945a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 1,541,384,960 parameters.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6zRjGcQUx5Q"
      },
      "source": [
        "Below is the function which runs a source langauge to infer over X-eng translations.\n",
        "\n",
        "The parameters defined under `options` is consistent with the example [notebook](https://github.com/openai/whisper/blob/main/notebooks/Multilingual_ASR.ipynb) shared by Whisper for multilingual translation on its github implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sSaBRfdy1mfy"
      },
      "outputs": [],
      "source": [
        "def whisper_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  options = dict(language=src_lang, beam_size=5, best_of=5)\n",
        "  # transcribe_options = dict(task=\"transcribe\",**options))\n",
        "  translate_options = dict(task=\"translate\",**options)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "  # transcriptions = []\n",
        "  # gt_transcripts=[]\n",
        "\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio = item['file']\n",
        "\n",
        "      translation = model.transcribe(audio, **translate_options)[\"text\"]\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "      # transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n",
        "      # transcriptions.append(transcription)\n",
        "      # gt_transcripts.append(item['sentence'])\n",
        "  return translations, gt_translations\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EjE17ileSj_w"
      },
      "outputs": [],
      "source": [
        "whisper_bleu_score = collections.defaultdict(dict)\n",
        "whisper_translations = collections.defaultdict(dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tGSG328iA2R",
        "outputId": "23e48094-a810-4741-f22f-14bcb98d3429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1464/1759 [1:41:57<13:19,  2.71s/it]"
          ]
        }
      ],
      "source": [
        "for src in lang_codes:\n",
        "  translations, ground_truth = whisper_inference(src)\n",
        "  whisper_translations[src] = translations\n",
        "  whisper_bleu_score[src] = evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "  with open(os.path.join(results_directory,'whisper_eval.json'), 'w') as f:\n",
        "    json.dump(whisper_bleu_score, f, indent=4)\n",
        "  with open(os.path.join(results_directory,'whisper_translations.json'), 'w') as f:\n",
        "    json.dump(whisper_translations, f, indent=4)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clear GPU memory\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YY2R064WJSH5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYrhKqeBeU_G"
      },
      "source": [
        "## Load XLS-R (2B) model and do infernece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the huggingface ðŸ¤— transformers implementation of XLS-R (2B) model.\n",
        "\n",
        "We would be using `wav2vec2-xls-r-2b-21-to-en` model as it is a encoder-decoder model which has been fine-tuned to support languages in CoVoST2 X-eng translations. The details about which can be found [here](https://huggingface.co/facebook/wav2vec2-xls-r-2b-21-to-en)"
      ],
      "metadata": {
        "id": "5hKq98-nJ0As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Please beaware that the reference code given for inference at huggingface doesn't work, please use the below implementation"
      ],
      "metadata": {
        "id": "2i9Ndk90LJ9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAboaE2kgyyG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import SpeechEncoderDecoderModel,MBart50Tokenizer\n",
        "from datasets import load_dataset\n",
        "#loading the MBart50Tokenizer as decoder is MBart50 transformer model\n",
        "tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i09XNcgD-3h4"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(\"facebook/wav2vec2-xls-r-2b-21-to-en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwwCHQ6UZnRf"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress UserWarnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the pipleine function to put together the tokenizer, feature extractor and the actual model"
      ],
      "metadata": {
        "id": "vvpiR5YYOOgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnWbf-JEICo2"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "asr=pipeline(model=\"facebook/wav2vec2-xls-r-2b-21-to-en\",tokenizer=tokenizer,feature_extractor=feature_extractor,device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRwFVWA1pUte"
      },
      "outputs": [],
      "source": [
        "def xlsr_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio = item['file']\n",
        "\n",
        "      translation = asr(audio)[\"text\"]\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "  return translations, gt_translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiZPjlBJXDD1"
      },
      "outputs": [],
      "source": [
        "xlsr_bleu_score=collections.defaultdict(dict)\n",
        "xlsr_translations = collections.defaultdict(dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty8crgbd_bfM"
      },
      "outputs": [],
      "source": [
        "for src in lang_codes:\n",
        "    translations, ground_truth=xlsr_inference(src)\n",
        "    xlsr_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "    xlsr_translations[src]=translations\n",
        "    with open(os.path.join(results_directory,'xlsr_eval.json'), 'w') as f:\n",
        "      json.dump(xlsr_bleu_score, f, indent=4)\n",
        "    with open(os.path.join(results_directory,'xlsr_translations.json'), 'w') as f:\n",
        "    json.dump(xlsr_translations, f, indent=4)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpyW1Gmx_jRV",
        "outputId": "37850e5c-2347-4b59-8c56-ae0cdcf2c5f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {'low_res': {'mn': 1.877,\n",
              "              'ta': 0.613,\n",
              "              'lv': 20.774,\n",
              "              'et': 11.186,\n",
              "              'cy': 14.671,\n",
              "              'sl': 19.117,\n",
              "              'ja': 4.102,\n",
              "              'tr': 16.774,\n",
              "              'ar': 16.991,\n",
              "              'nl': 31.883,\n",
              "              'sv-SE': 30.987,\n",
              "              'id': 16.255},\n",
              "             'mid_res': {'zh-CN': 9.475,\n",
              "              'fa': 13.073,\n",
              "              'it': 35.034,\n",
              "              'ru': 39.44,\n",
              "              'pt': 42.012},\n",
              "             'high_res': {'ca': 33.813,\n",
              "              'de': 33.486,\n",
              "              'fr': 37.614,\n",
              "              'es': 39.166}})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xlsr_bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5TdYiQnS6P"
      },
      "source": [
        "## Load Seamless model and do infernece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_type = \"medium\"\n",
        "model_type = \"large\""
      ],
      "metadata": {
        "id": "ryeCshZX1pq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1YkQLMTuF8Q",
        "outputId": "c1ffbbaf-a527-47f4-d6cf-b274ebba11b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cc/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/cc/.local/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoProcessor, SeamlessM4TModel\n",
        "\n",
        "model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)\n",
        "model.cuda()\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-\"+model_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01h2MNzOnibE"
      },
      "outputs": [],
      "source": [
        "def seamless_inference(src_lang):\n",
        "  x_en=load_dataset(\"covost2\",src_lang+\"_en\",data_dir=\"data/\"+src_lang,split=\"test\",trust_remote_code=True)\n",
        "\n",
        "  translations = []\n",
        "  gt_translations = []\n",
        "\n",
        "\n",
        "  for item in tqdm(x_en):\n",
        "      audio_sample = item['audio']\n",
        "      audio_inputs = processor(audios=audio_sample[\"array\"], return_tensors=\"pt\",sampling_rate=16000)\n",
        "      audio_inputs = {k: v.to('cuda') for k, v in audio_inputs.items()}\n",
        "\n",
        "      output_tokens = model.generate(**audio_inputs, tgt_lang=\"eng\",generate_speech=False)\n",
        "      translation=processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
        "      translations.append(translation)\n",
        "      gt_translations.append(item['translation'])\n",
        "\n",
        "  return translations, gt_translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDEWrOs1pzYE"
      },
      "outputs": [],
      "source": [
        "seamless_bleu_score=collections.defaultdict(dict)\n",
        "seamless_translations=collections.defaultdict(dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLJm88V5t1DY",
        "outputId": "7ce40f6a-d72a-4bf1-e4d6-042c1666e56b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1759/1759 [12:11<00:00,  2.41it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 786/786 [03:29<00:00,  3.75it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1629/1629 [06:33<00:00,  4.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1571/1571 [13:28<00:00,  1.94it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 690/690 [03:42<00:00,  3.10it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:46<00:00,  3.38it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 684/684 [03:21<00:00,  3.40it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1629/1629 [08:26<00:00,  3.21it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1695/1695 [07:31<00:00,  3.76it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1699/1699 [08:25<00:00,  3.36it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1595/1595 [06:42<00:00,  3.97it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [03:24<00:00,  4.12it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4898/4898 [32:36<00:00,  2.50it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3445/3445 [17:31<00:00,  3.28it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8951/8951 [56:18<00:00,  2.65it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6300/6300 [41:09<00:00,  2.55it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4023/4023 [20:34<00:00,  3.26it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12730/12730 [1:18:42<00:00,  2.70it/s]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6766/13511 [40:45<37:00,  3.04it/s]"
          ]
        }
      ],
      "source": [
        "for src in lang_codes:\n",
        "    translations, ground_truth=seamless_inference(src)\n",
        "    seamless_bleu_score[src]=evaluate_sacre_bleu(translations=translations,gt_translations=ground_truth)\n",
        "    seamless_translations[src]=translations\n",
        "\n",
        "    with open(os.path.join(results_directory,'seamless_'+model_type+'_eval.json'), 'w') as f:\n",
        "      json.dump(xlsr_bleu_score, f, indent=4)\n",
        "    with open(os.path.join(results_directory,'seamless_'+model_type+'_translations.json'), 'w') as f:\n",
        "    json.dump(xlsr_translations, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTlATNFoUvm7",
        "outputId": "3db0ba9f-08ad-444c-a006-b58a4313958f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(dict,\n",
              "            {'low_res': {'mn': 7.378,\n",
              "              'ta': 3.931,\n",
              "              'lv': 26.902,\n",
              "              'et': 26.298,\n",
              "              'cy': 55.276,\n",
              "              'sl': 38.32,\n",
              "              'ja': 19.69,\n",
              "              'tr': 30.647,\n",
              "              'ar': 45.732,\n",
              "              'nl': 40.112,\n",
              "              'sv-SE': 37.972,\n",
              "              'id': 50.455},\n",
              "             'mid_res': {'zh-CN': 19.911,\n",
              "              'fa': 25.213,\n",
              "              'it': 38.805,\n",
              "              'ru': 47.881,\n",
              "              'pt': 49.055},\n",
              "             'high_res': {'ca': 37.969,\n",
              "              'de': 38.009,\n",
              "              'fr': 40.724,\n",
              "              'es': 40.639}})"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seamless_bleu_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APlPgV4XuV41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s8cjKrsvTJ6",
        "outputId": "f8e7af91-b0e7-4d27-a8ee-43e22a551336"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.29719047619048"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3q56_7EvbsR",
        "outputId": "ce2492ba-ce99-4217-a895-1ff281bd9873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34.32947619047619"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}